{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5586a44d",
   "metadata": {
    "papermill": {
     "duration": 0.006181,
     "end_time": "2022-06-27T09:44:10.193454",
     "exception": false,
     "start_time": "2022-06-27T09:44:10.187273",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99299206",
   "metadata": {
    "papermill": {
     "duration": 0.004688,
     "end_time": "2022-06-27T09:44:10.202999",
     "exception": false,
     "start_time": "2022-06-27T09:44:10.198311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UW-Madison GI Tract Image Segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071fd31",
   "metadata": {
    "papermill": {
     "duration": 0.004129,
     "end_time": "2022-06-27T09:44:10.211584",
     "exception": false,
     "start_time": "2022-06-27T09:44:10.207455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aae802f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:10.223153Z",
     "iopub.status.busy": "2022-06-27T09:44:10.222406Z",
     "iopub.status.idle": "2022-06-27T09:44:41.942704Z",
     "shell.execute_reply": "2022-06-27T09:44:41.941545Z"
    },
    "papermill": {
     "duration": 31.729502,
     "end_time": "2022-06-27T09:44:41.945497",
     "exception": false,
     "start_time": "2022-06-27T09:44:10.215995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "!pip install -q segmentation_models_pytorch\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c08b6",
   "metadata": {
    "papermill": {
     "duration": 0.004472,
     "end_time": "2022-06-27T09:44:41.954907",
     "exception": false,
     "start_time": "2022-06-27T09:44:41.950435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CONFIGURAZIONE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fc4a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:41.966887Z",
     "iopub.status.busy": "2022-06-27T09:44:41.965938Z",
     "iopub.status.idle": "2022-06-27T09:44:41.971483Z",
     "shell.execute_reply": "2022-06-27T09:44:41.970350Z"
    },
    "papermill": {
     "duration": 0.013806,
     "end_time": "2022-06-27T09:44:41.973448",
     "exception": false,
     "start_time": "2022-06-27T09:44:41.959642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "SEED = 4321\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE = 0.2\n",
    "LEARNING_RATE = 2e-3\n",
    "N_EPOCHS = 6\n",
    "IMG_SIZE = (128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b6bc4",
   "metadata": {
    "papermill": {
     "duration": 0.004263,
     "end_time": "2022-06-27T09:44:41.982422",
     "exception": false,
     "start_time": "2022-06-27T09:44:41.978159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FUNZIONI UTILI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62d8763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:41.993889Z",
     "iopub.status.busy": "2022-06-27T09:44:41.992771Z",
     "iopub.status.idle": "2022-06-27T09:44:42.008757Z",
     "shell.execute_reply": "2022-06-27T09:44:42.007887Z"
    },
    "papermill": {
     "duration": 0.023941,
     "end_time": "2022-06-27T09:44:42.010747",
     "exception": false,
     "start_time": "2022-06-27T09:44:41.986806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1464):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_loss(loss, val_loss):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.xticks(range(1,len(loss)+1))\n",
    "    plt.plot(range(1,len(loss)+1), loss, label='train')\n",
    "    plt.plot(range(1,len(val_loss)+1), val_loss, label='val')\n",
    "    plt.title('loss')\n",
    "    plt.legend()\n",
    "    #plt.savefig('loss.png')\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ddaa77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:42.021653Z",
     "iopub.status.busy": "2022-06-27T09:44:42.020898Z",
     "iopub.status.idle": "2022-06-27T09:44:42.028174Z",
     "shell.execute_reply": "2022-06-27T09:44:42.027256Z"
    },
    "papermill": {
     "duration": 0.015109,
     "end_time": "2022-06-27T09:44:42.030496",
     "exception": false,
     "start_time": "2022-06-27T09:44:42.015387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e7e27",
   "metadata": {
    "papermill": {
     "duration": 0.00437,
     "end_time": "2022-06-27T09:44:42.039602",
     "exception": false,
     "start_time": "2022-06-27T09:44:42.035232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CREAZIONE TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245ee6ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:42.050301Z",
     "iopub.status.busy": "2022-06-27T09:44:42.049936Z",
     "iopub.status.idle": "2022-06-27T09:44:55.733868Z",
     "shell.execute_reply": "2022-06-27T09:44:55.732681Z"
    },
    "papermill": {
     "duration": 13.692299,
     "end_time": "2022-06-27T09:44:55.736433",
     "exception": false,
     "start_time": "2022-06-27T09:44:42.044134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>stomach</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>0001</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>0002</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0003</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>0003</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0004</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>0004</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0005</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>0005</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38491</th>\n",
       "      <td>case30_day0_slice_0140</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0140</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38492</th>\n",
       "      <td>case30_day0_slice_0141</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0141</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38493</th>\n",
       "      <td>case30_day0_slice_0142</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0142</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38494</th>\n",
       "      <td>case30_day0_slice_0143</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0143</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38495</th>\n",
       "      <td>case30_day0_slice_0144</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0144</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38496 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id large_bowel small_bowel stomach  case  day  \\\n",
       "0      case123_day20_slice_0001                                   123   20   \n",
       "1      case123_day20_slice_0002                                   123   20   \n",
       "2      case123_day20_slice_0003                                   123   20   \n",
       "3      case123_day20_slice_0004                                   123   20   \n",
       "4      case123_day20_slice_0005                                   123   20   \n",
       "...                         ...         ...         ...     ...   ...  ...   \n",
       "38491    case30_day0_slice_0140                                    30    0   \n",
       "38492    case30_day0_slice_0141                                    30    0   \n",
       "38493    case30_day0_slice_0142                                    30    0   \n",
       "38494    case30_day0_slice_0143                                    30    0   \n",
       "38495    case30_day0_slice_0144                                    30    0   \n",
       "\n",
       "      slice                                               path  width  height  \n",
       "0      0001  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "1      0002  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "2      0003  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "3      0004  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "4      0005  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "...     ...                                                ...    ...     ...  \n",
       "38491  0140  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "38492  0141  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "38493  0142  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "38494  0143  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "38495  0144  /kaggle/input/uw-madison-gi-tract-image-segmen...    266     266  \n",
       "\n",
       "[38496 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the training dataframe and display the initial dataframe\n",
    "DATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation/\"\n",
    "TRAIN_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation/train\"\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "\n",
    "temp_df = pd.DataFrame({\"id\": train_df[\"id\"][::3]})\n",
    "temp_df[\"large_bowel\"] = train_df[\"segmentation\"][::3].values\n",
    "temp_df[\"small_bowel\"] = train_df[\"segmentation\"][1::3].values\n",
    "temp_df[\"stomach\"] = train_df[\"segmentation\"][2::3].values\n",
    "\n",
    "train_df = temp_df\n",
    "\n",
    "train_df[\"case\"] = train_df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n",
    "train_df[\"day\"] = train_df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n",
    "train_df[\"slice\"] = train_df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_images = glob(os.path.join(DATA_DIR + 'train', \"**\", \"*.png\"), recursive=True)\n",
    "train_df[\"path\"] =all_images\n",
    "\n",
    "train_df[\"width\"] = train_df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[1]))\n",
    "train_df[\"height\"] = train_df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[2]))\n",
    "\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "train_df.fillna('',inplace=True)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1643e1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:55.748378Z",
     "iopub.status.busy": "2022-06-27T09:44:55.747998Z",
     "iopub.status.idle": "2022-06-27T09:44:55.759414Z",
     "shell.execute_reply": "2022-06-27T09:44:55.758359Z"
    },
    "papermill": {
     "duration": 0.020188,
     "end_time": "2022-06-27T09:44:55.761781",
     "exception": false,
     "start_time": "2022-06-27T09:44:55.741593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, subset=\"train\"):\n",
    "        self.df = df\n",
    "        self.subset = subset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        masks = np.zeros((IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)\n",
    "        img_path=self.df['path'].iloc[index]\n",
    "        w=self.df['width'].iloc[index]\n",
    "        h=self.df['height'].iloc[index]\n",
    "        img = self.__load_img(img_path)\n",
    "        if self.subset == 'train':\n",
    "            for k,j in zip([0,1,2],[\"large_bowel\",\"small_bowel\",\"stomach\"]):\n",
    "                rles=self.df[j].iloc[index]\n",
    "                mask = rle_decode(rles, shape=(h, w, 1))\n",
    "                mask = cv2.resize(mask, IMG_SIZE)\n",
    "                masks[:,:,k] = mask\n",
    "        \n",
    "        masks = masks.transpose(2, 0, 1)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "\n",
    "        if self.subset == 'train': return torch.tensor(img), torch.tensor(masks)\n",
    "        else: return torch.tensor(img)\n",
    "        \n",
    "    def __load_img(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        img = (img - img.min())/(img.max() - img.min())*255.0 \n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
    "        img = img.astype(np.float32) /255.\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387d20d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:55.773603Z",
     "iopub.status.busy": "2022-06-27T09:44:55.773199Z",
     "iopub.status.idle": "2022-06-27T09:44:55.801392Z",
     "shell.execute_reply": "2022-06-27T09:44:55.800388Z"
    },
    "papermill": {
     "duration": 0.036816,
     "end_time": "2022-06-27T09:44:55.803841",
     "exception": false,
     "start_time": "2022-06-27T09:44:55.767025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df = train_df.sample(frac=VAL_SIZE)\n",
    "train_df = train_df.drop(val_df.index).reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "train_dataset = GIDataset(train_df)\n",
    "val_dataset = GIDataset(val_df)\n",
    "\n",
    "# Creation of Pytorch DataLoaders with shuffle=True for the traing phase\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc116a",
   "metadata": {
    "papermill": {
     "duration": 0.004734,
     "end_time": "2022-06-27T09:44:55.813916",
     "exception": false,
     "start_time": "2022-06-27T09:44:55.809182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9654e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:44:55.826530Z",
     "iopub.status.busy": "2022-06-27T09:44:55.826151Z",
     "iopub.status.idle": "2022-06-27T09:45:00.576348Z",
     "shell.execute_reply": "2022-06-27T09:45:00.575392Z"
    },
    "papermill": {
     "duration": 4.759646,
     "end_time": "2022-06-27T09:45:00.578752",
     "exception": false,
     "start_time": "2022-06-27T09:44:55.819106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7f39be91674c85a8fc827b4dffef29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/30.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "        encoder_name='efficientnet-b1',      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.\n",
    "        classes=3,        # model output channels (number of classes in your dataset)\n",
    "        activation=None,\n",
    "    )\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = smp.losses.DiceLoss(mode='multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c674d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T09:45:00.591114Z",
     "iopub.status.busy": "2022-06-27T09:45:00.590780Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-06-27T09:45:00.584213",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 6 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   0%|          | 0/482 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   0%|          | 1/482 [00:10<1:24:26, 10.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   0%|          | 2/482 [00:20<1:19:45,  9.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   1%|          | 3/482 [00:29<1:19:08,  9.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   1%|          | 4/482 [00:38<1:15:33,  9.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   1%|          | 5/482 [00:47<1:13:03,  9.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   1%|          | 6/482 [00:56<1:12:56,  9.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   1%|▏         | 7/482 [01:05<1:11:46,  9.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train :   2%|▏         | 8/482 [01:13<1:09:52,  8.84s/it]"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "history = {\n",
    "    'train_loss' : [],\n",
    "    'val_loss' : []\n",
    "}\n",
    "#----------TRAINING\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Scaler for mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Setup for training with gpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "loss_fn.to(device)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, N_EPOCHS):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, N_EPOCHS))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode: Dropout layers are active\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            y_pred = model(images)\n",
    "            loss   = loss_fn(y_pred, masks)\n",
    "\n",
    "        # Perform a backward pass to compute the gradients in MIXED precision\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Unscales the gradients of optimizer's assigned params in-place before the gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This helps and prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient in MIXED precision\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    # Compute the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode: the dropout layers behave differently\n",
    "    model.eval()\n",
    "\n",
    "    total_val_loss = 0\n",
    "\n",
    "    pbar = tqdm(enumerate(validation_dataloader), total=len(validation_dataloader), desc='Validation ')\n",
    "    for step, (images, masks) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad():  \n",
    "            y_pred = model(images)\n",
    "            loss   = loss_fn(y_pred, masks)\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "    # Compute the average loss over all of the batches.\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    \n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c7361",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T20:47:51.285004Z",
     "iopub.status.idle": "2022-06-26T20:47:51.285796Z",
     "shell.execute_reply": "2022-06-26T20:47:51.285531Z",
     "shell.execute_reply.started": "2022-06-26T20:47:51.285502Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history['train_loss'], history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a6331",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T20:47:51.28767Z",
     "iopub.status.idle": "2022-06-26T20:47:51.288647Z",
     "shell.execute_reply": "2022-06-26T20:47:51.288389Z",
     "shell.execute_reply.started": "2022-06-26T20:47:51.288363Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.cpu(), '/kaggle/working/trained_unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb517be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:02:36.27612Z",
     "iopub.status.busy": "2022-06-26T16:02:36.27575Z",
     "iopub.status.idle": "2022-06-26T16:02:44.940554Z",
     "shell.execute_reply": "2022-06-26T16:02:44.939465Z",
     "shell.execute_reply.started": "2022-06-26T16:02:36.27609Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(validation_dataloader), total=len(validation_dataloader), desc='Test ')\n",
    "    preds = []\n",
    "    for step, (images, masks) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        preds.append(model(images)) # .squeeze(0) # removing batch axis\n",
    "        #preds   = nn.Sigmoid()(out) # removing channel axis\n",
    "    preds = torch.cat(preds,dim=0).cpu().numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075146a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## TEST SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8415302",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T18:46:18.383844Z",
     "iopub.status.idle": "2022-06-26T18:46:18.384605Z",
     "shell.execute_reply": "2022-06-26T18:46:18.38437Z",
     "shell.execute_reply.started": "2022-06-26T18:46:18.384345Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "\n",
    "test_df = pd.DataFrame({\"id\": sub_df[\"id\"][::3]})\n",
    "test_df[\"large_bowel\"] = sub_df[\"segmentation\"][::3].values\n",
    "test_df[\"small_bowel\"] = sub_df[\"segmentation\"][1::3].values\n",
    "test_df[\"stomach\"] = sub_df[\"segmentation\"][2::3].values\n",
    "\n",
    "test_df[\"case\"] = test_df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n",
    "test_df[\"day\"] = test_df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n",
    "test_df[\"slice\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n",
    "all_images = glob(os.path.join(DATA_DIR + 'test', \"**\", \"*.png\"), recursive=True)\n",
    "test_df[\"path\"] =all_images\n",
    "\n",
    "test_df[\"width\"] = test_df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[1]))\n",
    "test_df[\"height\"] = test_df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[2]))\n",
    "\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "test_df.fillna('',inplace=True)\n",
    "\n",
    "test_dataset = GIDatatset(test_df, subset='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec1904",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "\n",
    "pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc='Test ')\n",
    "for step, (images, masks) in pbar:         \n",
    "    images = images.to(device, dtype=torch.float)\n",
    "\n",
    "    batch_size = images.size(0)\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        y_pred = model(images)\n",
    "        preds.append(y_pred.cpu().numpy())\n",
    "\n",
    "print(\"  Test took: {:}\".format(validation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c958a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:13:29.844184Z",
     "iopub.status.busy": "2022-06-26T16:13:29.843512Z",
     "iopub.status.idle": "2022-06-26T16:13:31.394634Z",
     "shell.execute_reply": "2022-06-26T16:13:31.393707Z",
     "shell.execute_reply.started": "2022-06-26T16:13:29.84414Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "masks = []\n",
    "for i in range(len(preds)):\n",
    "    for j in range(3):\n",
    "        class_pred = preds[i,j,:,:]\n",
    "        pred_img = cv2.resize(class_pred, (val_df['width'].iloc[i], val_df['height'].iloc[i]), interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n",
    "        pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n",
    "        masks.append(pred_img)\n",
    "sub_df['prediction'] = pd.Series([rle_encode(m) for m in masks])\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-27T09:44:01.585965",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}